<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Analysis of catch rate estimation with biased sampling strategies">

<title>Impact of sampling bias on catch rate estimation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="reportv2_files/libs/clipboard/clipboard.min.js"></script>
<script src="reportv2_files/libs/quarto-html/quarto.js"></script>
<script src="reportv2_files/libs/quarto-html/popper.min.js"></script>
<script src="reportv2_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="reportv2_files/libs/quarto-html/anchor.min.js"></script>
<link href="reportv2_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="reportv2_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="reportv2_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="reportv2_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="reportv2_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Impact of sampling bias on catch rate estimation</h1>
</div>

<div>
  <div class="description">
    <p>Analysis of catch rate estimation with biased sampling strategies</p>
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">Invalid Date</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="authors" class="level3">
<h3 class="anchored" data-anchor-id="authors">Authors</h3>
<p><em>CJ Brown</em> Institute for Marine and Antarctic Studies, Hobart, Tasmania. (contact: c.j.brown@utas.edu.au)</p>
<p>The Nature Conservancy…</p>
</section>
<section id="the-problem" class="level2">
<h2 class="anchored" data-anchor-id="the-problem">The problem</h2>
<p>Electronic monitoring (EM) uses video cameras and sensors to observe and record fishing activities. The electronic records are later be reviewed as a source of information on fishing activities that is independent of logbooks.</p>
<p>With the growth of electronic monitoring programs around the world over the past decade, various approaches to sampling have been used depending on the fishery, monitoring goals, prevalence of species being monitored, and human capacity to perform data review.</p>
<p>As EM has become a necessary tool for meeting independent fishery observation benchmarks set by Regional Fishery Management Organizations (RFMOs) and sustainability certifications such as the Marine Stewardship Council (MSC), stakeholders have expressed a need for additional guidance on how monitoring gets applied in fisheries to meet target observation rates. Traditionally performed by human observers, EM programs often use a sub-sampling procedure to generate catch statistics that are representative of relevant fishing events, or of entire fisheries.</p>
<p>These sampling procedures for EM programs have been applied in numerous ways and given that the coverage and sampling dynamics are typically different than traditional human observer approaches, more guidance on how sampling procedures can effect data quality and accuracy is needed. Potential issues include sampling bias that causes over or under estimation of catch events [also add TEP interactions?], variation that creates uncertainty about true catch rates and potential to miss important events.</p>
<p>As one example, the Marine Stewardship Council (MSC) requires 30% coverage for independent monitoring of fisheries on the high seas to track statistics like market species catch rate and bycatch. MSC is considering a revised threshold for the evidence requirement framework. However, more guidance is needed to direct exactly how that 20-30% should be chosen. This creates a potential problem: nations and fishing companies might choose to monitor only their “best” 20-30% of vessels or trips - those with the lowest bycatch rates - making their overall performance look better than it actually is.</p>
<p>This study used a computer simulation and a hypothetical fishery to investigate whether different ways of selecting which fishing activities to monitor would give accurate estimates of true catch rates, or if some selection methods, referred to as “scenarios”, would be biased and misleading. We provide narratives for how three different scenarios for monitoring 30% of fishing activities affect the accuracy of estimated catch rates for both target and bycatch.</p>
<p><strong>Why This Matters</strong>: If monitoring is biased toward “cleaner” vessels or trips, regulators and the public might think a fishery is performing better than it really is, potentially allowing harmful fishing practices to continue undetected and undeterred.</p>
</section>
<section id="how-the-study-was-done" class="level2">
<h2 class="anchored" data-anchor-id="how-the-study-was-done">How The Study Was Done</h2>
<section id="catch-model" class="level3">
<h3 class="anchored" data-anchor-id="catch-model">Catch model</h3>
<p>We created a computer simulation that modeled a fictional longline tuna fishing fleet with 50 vessels, based on dynamics of an actual fleet <span class="citation" data-cites="brown2021electronic">(e.g. <a href="#ref-brown2021electronic" role="doc-biblioref">Brown et al. 2021</a>)</span>. The fictional fishery’s manager has to make a decision about how to allocate monitoring and review of data for the coming year. We assumed the manager knew the number of vessels, but not the amount of fishing they would do or how much they would catch.</p>
<p>We modelled fishing activities over one year. During the year each of the 50 vessels made one or more fishing trips. On each fishing trip they set one or more longlines. We then modelled catch on each longline set.</p>
<p>The number of trips per vessel was randomized to reflect variation that is evident in real long line fisheries. For example, some vessels may only make 2-3 trips in a year whereas others may make more than 10. Likewise, the number of sets per trip was randomized, using a mean of 26 sets per trip. Differences in the number of sets represent trips of different durations. We then modelled catch on each longline set.</p>
<p>In a real fishery, catches vary across sets, due to differences in time, location, fishing gear, fisher behaviour and many other factors. From the perspective of monitoring we see differences in catch across sets. We also see differences in average catch per set across trips. This trip-to-trip variation may be caused by different locations fished, different times and different fishing practices. We also see differences in average catch per set across vessels. This vessel-to-vessel variation reflects different gears, different levels of fisher skill and knowledge and differences in what vessels are targetting. We estimated these three sources of variation from our real data and included them in our simulation. These were included as random variation in average: set-to-set catches, trip-to-trip catches per set and vessel-to-vessel catches per set.</p>
<p>We modelled five categories of catch events with different average catch rates:</p>
<ol type="1">
<li>A market species that is a target of fishing and is caught commonly, (e.g.&nbsp;yellowfin tuna)</li>
<li>A market species similar to (1) except that there was higher variability in catch rates across <strong>trips</strong>. This represents a situation where captains have greater flexibility to modify their bycatch for example they may fish in different regions, use different gear, or go on shorter trips.</li>
<li>A market species similar to (1) except that there was higher variability in catch rates across <strong>vessels</strong>. For example, different vessel captains may have different levels of knowledge about avoiding bycatch or use different fishing gears.</li>
<li>A by-product species that is caught less consistently than the main market species (e.g.&nbsp;blue shark)</li>
<li>A rare bycatch species that is caught inconsistently, but is a vulnerable species and/or a designated endangered, threatened, or protected species (e.g.&nbsp;green turtles). The rare bycatch species could also be representative of other rare events, such as trans-shipment</li>
</ol>
</section>
<section id="monitoring-and-review-model" class="level3">
<h3 class="anchored" data-anchor-id="monitoring-and-review-model">Monitoring and review model</h3>
<p>We considered different scenarios for <em>monitoring</em> the fishing activity and <em>reviewing</em> the monitoring data. We use the term <em>monitor</em> to refer to vessels, trips or sets that had human observers or electronic monitoring present. We use the term <em>coverage</em> to indicate the percentage of the sets in a year that were monitored. We use the term <em>review</em> to refer to monitoring data that was obtained and analyzed. What was important in our simulations was the rate of review and whether that review was biased towards some trips or vessels.</p>
<p>We present three monitoring scenarios. For all scenarios we assume data review is of whole sets.</p>
<section id="scenario-1-monitoring-100-of-fishing-activity-and-reviewing-30-of-all-sets" class="level4">
<h4 class="anchored" data-anchor-id="scenario-1-monitoring-100-of-fishing-activity-and-reviewing-30-of-all-sets">Scenario 1: Monitoring 100% of fishing activity and reviewing 30% of all sets</h4>
<p>Monitor 100% of fishing activity on every vessel in the fleet with random review of 30% of sets. This scenario reflects a fleet with 100% EM coverage and 30% review of those sets.</p>
</section>
<section id="scenario-2-monitor-and-review-all-sets-on-30-of-all-trips" class="level4">
<h4 class="anchored" data-anchor-id="scenario-2-monitor-and-review-all-sets-on-30-of-all-trips">Scenario 2: Monitor and review all sets on 30% of all trips</h4>
<p>Review all data from 30% of trips. This scenario reflects human observers who participate in trips and collect data for all fishing on those trips.</p>
<p>We explored two protocols for how monitoring and review of trips was allocated. (1) Trips selected at random. (2) Bias towards trips with lower than average catch rates. The bias simulates situations where captains attempt to decrease the probability of catching bycatch when fishing activity is under human observation, such as by using different gear.</p>
</section>
<section id="scenario-3-reviewing-data-from-whole-vessels" class="level4">
<h4 class="anchored" data-anchor-id="scenario-3-reviewing-data-from-whole-vessels">Scenario 3: Reviewing data from whole vessels</h4>
<p>Review all data from 30% of vessels. This scenario reflects electronic monitoring systems being installed on 30% of vessels in the fleet, and then all fishing sets from those vessels being reviewed.</p>
<p>We explored two protocols for how monitoring and review was allocated to vessels (that mirrored the two protocols under Scenario 2). (1) Vessels selected at random. (2) Bias towards vessels with lower than average catch rates. This simulates situations where a nation or fishery attempt to influence the data by deploying cameras on vessels with the best practices.</p>
</section>
</section>
<section id="simulations" class="level3">
<h3 class="anchored" data-anchor-id="simulations">Simulations</h3>
<p>Our aim was to explore the likelihood that the three fictional monitoring scenarios would obtain unbiased catch rates when applied to each of the five catch event categories. We simulated a 1000 replicates fishing activity, to capture the full range of variation described for the catch rates. For each of the 1000 replicates we applied each of the three monitoring scenarios along with their respective allocation protocols.</p>
<p>Our outcome statistic - mean bias - was the per cent difference between the mean catch rate as monitored and the true mean catch rate. We calculated mean bias for each catch event category across the 1000 replicates. This statistic represents, on average, how close each monitoring scenario gets to the true catch rate. The ideal situation is to have mean bias of 0%.</p>
<p>We were also interested in the variance in mean bias across the 1000 replicates. The variance represents the consistency in our monitoring results. For example the ideal outcome would be an average bias is 0% and a very low variance (e.g.&nbsp;1%). This result would indicate a very good chance of getting an accurate catch rate estimate in any given year of fishing.</p>
<p>We could also find that bias is 0%, but variance is high. Such a result would indicate that for any given year of fishing we are quite likely to obtain an estimated catch rate that is a long way off the true catch rate.</p>
</section>
<section id="conceptual-framework" class="level3">
<h3 class="anchored" data-anchor-id="conceptual-framework">Conceptual Framework</h3>
<p>** THIS SECTION TO BE UPDATED WITH NEW IMAGE FROM DANIELLE**</p>
<p>This conceptual figure illustrates how different monitoring approaches work. It shows a fishing fleet where dots represent different vessels and their fishing activities. Orange dots are monitored, grey dots are not monitored. The three sampling strategies are shown, demonstrating how monitoring coverage varies depending on the strategy used.</p>
<p><img src="images/conceptual_figure.png" class="img-fluid"></p>
<p>If monitoring is done randomly across all vessel in the fictional fleet we get an estimate of the catch rate that is representative of the true catch rate. If monitoring occurs on a subset of vessels in the fleet with 100% review or on a subset of trips across the fleet, and the selection of those units is biased towards lower catch rates, then the estimated catch rates will also be biased.</p>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="monitoring-and-review-scenarios" class="level2">
<h2 class="anchored" data-anchor-id="monitoring-and-review-scenarios">Monitoring and review scenarios</h2>
<section id="scenario-1-monitoring-100-of-fishing-activity-and-reviewing-30-of-all-sets-1" class="level4">
<h4 class="anchored" data-anchor-id="scenario-1-monitoring-100-of-fishing-activity-and-reviewing-30-of-all-sets-1">Scenario 1: Monitoring 100% of fishing activity and reviewing 30% of all sets</h4>
<p>This is the ideal scenario for 30% distribution of review across sets. We randomly selected 30% of all individual sets for review. This results in no bias on average and low variability across replicates for all species. The low variability means a manager can be confident that they will get an estimate of mean catch rate for any single year of fishing that is within 5-10% of the true catch rate.</p>
<p><img src="../../plots/plot_bias_percent_sets.png" class="img-fluid"></p>
</section>
<section id="scenario-2-monitor-and-review-all-sets-on-30-of-all-trips-1" class="level4">
<h4 class="anchored" data-anchor-id="scenario-2-monitor-and-review-all-sets-on-30-of-all-trips-1">Scenario 2: Monitor and review all sets on 30% of all trips</h4>
<p>Randomly selected 30% of fishing trips for monitoring by a human observer. All sets within the selected trips are reviewed.</p>
<p>The most important finding here was that catch rates were biased too low (by -40% to -80%) if monitoring was biased towards trips with lower than average catch rates meaning that the estimated mean catch rates could be as much as 80% lower than the true mean catch rate. This can happen if vessel captains are changing fishing practices or fishing locations when they know they have an observer on board.</p>
<p>The bias was worse when variation in catches across trips was higher, because in such fisheries vessel captains have more flexibility to change fishing practices.</p>
<p>Even without the biased allocation of observers there was still an issue with allocating monitoring on the basis of trips: there was higher variation across years compared to randomized monitoring of sets due to the clustering of data within trips. This means a manager cannot be as confident that the catch rate they measured is accurate. This issue was worst when there was also high variation across different trips.</p>
<p><img src="../../plots/plot_bias_percent_trips.png" class="img-fluid"></p>
</section>
<section id="scenario-3-reviewing-data-from-whole-vessels-1" class="level4">
<h4 class="anchored" data-anchor-id="scenario-3-reviewing-data-from-whole-vessels-1">Scenario 3: Reviewing data from whole vessels</h4>
<p>In this scenario, 30% of vessels are randomly selected for monitoring, and all trips and sets within those vessels are monitored and reviewed. Practically, this strategy can be achieved by installing electronic monitoring systems on a subset of vessels.</p>
<p>If monitoring and review was allocated to vessels with lower than average catch rates, then catch rates were biased too low (by up to 40% on average). This can happen if a fishery or nation is putting cameras on vessels that they know have the lowest bycatch rates.</p>
<p>The bias was worse when variation in catches across vessels was higher, because in such fisheries there is more flexibility to find the ‘best’ operators. For the vessel monitoring scenario, the levels of variation across replicate fishing years were greater than random set scenario, reflecting less confidence in catch rate estimates.</p>
<p><img src="../../plots/plot_bias_percent_vessels.png" class="img-fluid"></p>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>Monitoring 100% of fishing activity across a fleet with a random allocation of 30% review of sets is the best resource allocation policy for obtaining accurate catch statistics. Allocating 30% monitoring and review by vessels or trips will increase the variability such that managers will be less confident in the catch rates in any given year. Vessel and trip based scenarios also create the opportunity for gaming monitoring, resulting in biased catch rates.</p>
<p>In our simple scenario, vessel based allocation of monitoring resources was better than trip based allocation. This result may differ for different fisheries: it depends on the relative levels of variation in catch rates across vessels and trips. In a fishery where there is a lot of variation in catch rates across vessels, then this allocation strategy will look worse than a trip based strategy. For example, fisheries with a large range of different vessel types could have a much larger range of bycatch rates, and more potential for biased monitoring, than we found here.</p>
<p>An alternative to random allocation of monitoring and review is to stratify sampling by factors known to affect catch rates. For instnace, sampling could be stratified by vessel type, gear type and fishing location. Stratification would perform similarly to our ‘random sets’ scenario, possibly with even greater precision. However, stratification does require good understanding of the factors that affect catch rates. Again, bias is possible if important factors are missed when deciding how to stratify.</p>
</section>
<section id="box-1-20-coverage-of-sets" class="level2">
<h2 class="anchored" data-anchor-id="box-1-20-coverage-of-sets">Box 1: 20% coverage of sets</h2>
<p>Reducing the monitoring and review rate from 30% to 20% increased the variability in estimates across replicate years.</p>
<p><img src="../../plots/plot_bias_percent_bycatch_comparison.png" class="img-fluid"></p>
<p>ALT OPTION</p>
<p>Reducing the monitoring and review rate from 30% to 20% increased the variability in estimates across replicate years, it also increased the bias slightly when there was biased allocation of monitoring and review to trips or sets. s</p>
<p><img src="../../plots/plot_bias_percent_market_comparison.png" class="img-fluid"></p>
</section>
<section id="box-2-implications-of-monitoring-scenarios-for-bias-in-logbook-reporting" class="level2">
<h2 class="anchored" data-anchor-id="box-2-implications-of-monitoring-scenarios-for-bias-in-logbook-reporting">Box 2: Implications of monitoring scenarios for bias in logbook reporting</h2>
<p>Logbooks can misreport catch. Especially common is under-reporting of bycatch or TEP species, compared to observer data <span class="citation" data-cites="emery2019 brown2021electronic">(e.g. <a href="#ref-emery2019" role="doc-biblioref">Emery et al. 2019</a>; <a href="#ref-brown2021electronic" role="doc-biblioref">Brown et al. 2021</a>)</span>. Further, logbook records are often incomplete, and these data gaps may be biased towards some components of a fishing fleet <span class="citation" data-cites="bellanger2016">(e.g. <a href="#ref-bellanger2016" role="doc-biblioref">Bellanger, Macher, and Guyader 2016</a>)</span>. Scientific monitoring can be used to validate logbook records, estimate the rate of under-reporting and create an incentive for more accurate logbook reporting.</p>
<p>Observers can increase the accuracy of logbooks when fishers know they are being monitored and there are consequences for inaccurate logbooks<span class="citation" data-cites="emery2019 bremner2009">(e.g. <a href="#ref-emery2019" role="doc-biblioref">Emery et al. 2019</a>; <a href="#ref-bremner2009" role="doc-biblioref">Bremner et al. 2009</a>)</span>. For example, logbook records of turtle interactions went up by about 10 times when electronic monitoring was implemented in one long-line fishery <span class="citation" data-cites="emery2019">(<a href="#ref-emery2019" role="doc-biblioref">Emery et al. 2019</a>)</span>. Monitoring with 100% coverage, but partial review of randomly selected fishing events, creates an incentive for more accurate logbook reporting. The scientific credibility of logbook data is weaker when there is selective application of scientific monitoring, especially if it is biased towards trips or vessels with low bycatch rates.</p>
<p>Biased reporting of logbook data also has implications for stock assessments and quota allocations. Stock assessments can be biased to find the current stock status is either too conservative, or not conservative enough when catch data is under-reported <span class="citation" data-cites="vanbeveren2017 rudd2017">(<a href="#ref-vanbeveren2017" role="doc-biblioref">Van Beveren et al. 2017</a>; <a href="#ref-rudd2017" role="doc-biblioref">Rudd and Branch 2017</a>)</span>. The effects of catch under-reporting on stock assessments are complex, because assessments typically use complex models with many interacting factors. Key findings are that estimates of reference points will be unreliable if catch is under reported and that under-reporting is not accounted for <span class="citation" data-cites="vanbeveren2017">(<a href="#ref-vanbeveren2017" role="doc-biblioref">Van Beveren et al. 2017</a>)</span>. The biggest impact will also occur when the level of bias changes over years. In particular, if the level of bias increases, stock assessments will tend towards being less conservative (i.e.&nbsp;not recognizing overfishing), whereas if the level of bias reduces then stock assessments will tend towards being more conservative <span class="citation" data-cites="rudd2017">(<a href="#ref-rudd2017" role="doc-biblioref">Rudd and Branch 2017</a>)</span>.</p>
<p>When a fishery is restructured, catch shares are most often allocated on basis of historical catch data <span class="citation" data-cites="lynham2014">(<a href="#ref-lynham2014" role="doc-biblioref">Lynham 2014</a>)</span>. This can create an incentive to over-report in logbooks, if impending management changes are known about by fisheries. In the long-term, biased logbook data may also result in inequitable distribution of catch shares to fishers <span class="citation" data-cites="lynham2014">(<a href="#ref-lynham2014" role="doc-biblioref">Lynham 2014</a>)</span>.</p>
<hr>
</section>
<section id="advanced-methods" class="level2">
<h2 class="anchored" data-anchor-id="advanced-methods">Advanced methods</h2>
<p>We developed a general model for (1) simulating catch from a year’s worth of fishing activity and (2) simulating monitoring and review of that fishing catch. The model was split into a catch event module that modelled catch per set (Table S1) and a monitoring module that monitored monitoring and review of a sub-sample of all sets (Table S2). Simulation of catch and allocation of monitoring effort were both stochastic. This allowed us to explore how different monitoring scenarios impacted bias in estimated catch rates, with realistic levels of uncertainty. Specifically, our models accounted for uncertainty in: how much fishing activity happens in the coming year, how much catch is taken and by which vessels and on which trips, how monitoring effort is allocated to fishing activities, bias in how monitoring effort is allocated. These different sources of uncertainty were important because a plan for monitoring needs to be made before the fishing activity happens. With our model, we then simulated replicate years of fishing to obtain catch bias estimates along with ranges of variability.</p>
<p>For the catch model we simulated the number of trips per vessel and number of sets per trip, as well as catch per set. Trips per vessel and sets per trip were modelled as random numbers, to reflect real world variation in their numbers. The number of vessels was fixed at 50. Catch per set was modelled as a random number with additive components for vessel identity and trip identity. Therefore, catch events included covariation caused by vessel identity and trip identity.</p>
<p>The monitoring scenarios were modelled by randomly sampling sets, trips or vessels for data review. For the trip and vessel scenarios, a bias parameter was included such that review was biased towards trips or vessels with lower than average catch rates. We considered three monitoring scenarios, as described in the main text.</p>
<p>The random sampling of fishing activities and catch events was repeated to create 1000 datasets of annual fishing activities. Each monitoring scenario was then applied to each of the 1000 fishery datasets. The bias statistics were calculated as the difference between the true catch rate for that dataset and catch rate estimated by the monitoring scenario. The bias statistics therefore represent the difference between the estimated and true catch rates, conditional on each sample of catches. This conditional sampling is reflective of the situation managers face in the real world, where the observed catch rate differs from the true catch rate by an unknown amount. The confidence intervals across the 1000 simulations therefore represent our uncertainty about the accuracy of catch estimation in the coming year, given we know the number of vessels, but we don’t yet know the number of trips, sets or catches those vessels will take.</p>
<p>For a given monitoring scenario <em>M</em> (Table S2) and catch data <em>y</em>, the estimated catch rate per set can be calculated as the average catch per set that was monitored and reviewed:</p>
<p><span class="math display">\[
\hat{C} = \frac{\sum{(y_{v,t,s} * M_{v,t,s})}}{\sum{M_{v,t,s}}}
\]</span></p>
<p>Where <span class="math inline">\(y_{v,t,s}\)</span> is a matrix of catches and <span class="math inline">\(M_{v,t,s}\)</span> is a matrix of 0/1 that indicates whether a given set was monitored and reviewed.</p>
<p>The true catch rate in each scenario, <em>C</em> was simply average catch per set.</p>
<p>We calculated two bias statistics, the absolute bias:</p>
<p><span class="math display">\[
B = C - \hat{C}
\]</span></p>
<p>and the bias as a percentage of the catch rate:</p>
<p><span class="math display">\[
100 * B / C
\]</span></p>
<p>The percent bias is what we present above, because it puts all scenarios on the same scale. The absolute bias was much smaller for rarer species and therefore hard to visualize in comparisons.</p>
<p>All parameters were chosen to be representative of the Western Pacific longline tuna fleets, data given in <span class="citation" data-cites="brown2021electronic">Brown et al. (<a href="#ref-brown2021electronic" role="doc-biblioref">2021</a>)</span>, parameters are in Tables S3-s5. The analysis was performed with the R program <span class="citation" data-cites="Rprogram">(<a href="#ref-Rprogram" role="doc-biblioref">R Core Team 2024</a>)</span>. The code are available online at <a href="https://github.com/cbrown5/msc-review-rates" class="uri">https://github.com/cbrown5/msc-review-rates</a>.</p>
<p><strong>Table S1</strong> Model Equations and parameters of the catch event module</p>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 36%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Equation</th>
<th>Description</th>
<th>Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(T_{v} \sim dnegbin(\mu^{trips}, \theta^{trips})\)</span></td>
<td>Number of trips per vessel per year</td>
<td><span class="math inline">\(\mu^{trips}\)</span>: mean number of trips per year, <span class="math inline">\(\theta^{trips}\)</span>: dispersion in trips per year</td>
</tr>
<tr class="even">
<td><span class="math inline">\(x_{v} \sim dnorm(0, \sigma^{x})\)</span></td>
<td>Vessel-level random effect for catches per set</td>
<td><span class="math inline">\(\sigma^{x}\)</span>: vessel effect standard deviation</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(S_{v,t} \sim dnegbin(\mu^{sets}, \theta^{sets})\)</span></td>
<td>Number of sets per trip</td>
<td><span class="math inline">\(\mu^{sets}\)</span>: mean sets per trip, <span class="math inline">\(\theta^{sets}\)</span>: dispersion in sets per trip</td>
</tr>
<tr class="even">
<td><span class="math inline">\(z_{v,t} \sim dnorm(0, \sigma^z)\)</span></td>
<td>Trip-level random effect for catches</td>
<td><span class="math inline">\(\sigma^z\)</span>: trip effect standard deviation</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mu_{v,t} = \beta_{0} + z_{v,t} + x_{v}\)</span></td>
<td>Expected catch rate per set for a given trip</td>
<td><span class="math inline">\(\beta_{0}\)</span>: baseline catch rate per set</td>
</tr>
<tr class="even">
<td><span class="math inline">\(y_{v,t,s} \sim dnegbin(\mu_{v,t}, \theta^{catch})\)</span></td>
<td>Catch per set</td>
<td><span class="math inline">\(\theta^{catch}\)</span>: catch dispersion</td>
</tr>
</tbody>
</table>
<p><em>Notes:</em><br>
- <span class="math inline">\(V\)</span>: Number of vessels<br>
- <span class="math inline">\(T_{v}\)</span>: Number of trips for vessel <span class="math inline">\(v\)</span><br>
- <span class="math inline">\(S_{v,t}\)</span>: Number of sets for trip <span class="math inline">\(t\)</span> of vessel <span class="math inline">\(v\)</span><br>
- <span class="math inline">\(x_{v}\)</span>: Vessel random effect<br>
- <span class="math inline">\(z_{v,t}\)</span>: Trip random effect<br>
- <span class="math inline">\(\mu_{v,t}\)</span>: Expected catch rate for trip <span class="math inline">\(t\)</span> of vessel <span class="math inline">\(v\)</span><br>
- <span class="math inline">\(y_{v,t,s}\)</span>: Catch for set <span class="math inline">\(s\)</span> on trip <span class="math inline">\(t\)</span> of vessel <span class="math inline">\(v\)</span></p>
<p><strong>Table S2</strong> Model Equations and parameters of the monitoring module</p>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 36%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Equation</th>
<th>Description</th>
<th>Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\phi = \text{logit}(p)\)</span></td>
<td>Logit of base monitoring probability for set-based sampling</td>
<td><span class="math inline">\(p\)</span>: proportion of sets monitored (e.g., 0.3)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(M_{v,t,s} \sim \text{Bernoulli}(\text{logit}^{-1}(\phi))\)</span></td>
<td>Monitoring indicator for random sampling across sets</td>
<td><span class="math inline">\(M_{v,t,s}\)</span>: 1 if set monitored, 0 otherwise</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\phi_{v,t,s} = \text{logit}(p) + \text{bias}_{vessels} \cdot x_v\)</span></td>
<td>Logit of monitoring probability for vessel-based sampling, with bias</td>
<td><span class="math inline">\(\text{bias}_{vessels}\)</span>: vessel bias factor, <span class="math inline">\(x_v\)</span>: vessel random effect</td>
</tr>
<tr class="even">
<td><span class="math inline">\(M_{v,t,s} \sim \text{Bernoulli}(\text{logit}^{-1}(\phi_{v,t,s}))\)</span></td>
<td>Monitoring indicator for vessel-based sampling</td>
<td><span class="math inline">\(M_{v,t,s}\)</span>: 1 if set monitored, 0 otherwise</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\phi_{v,t,s} = \text{logit}(p) + \text{bias}_{trip} \cdot z_{v,t}\)</span></td>
<td>Logit of monitoring probability for trip-based sampling, with bias</td>
<td><span class="math inline">\(\text{bias}_{trip}\)</span>: trip bias factor, <span class="math inline">\(z_{v,t}\)</span>: trip random effect</td>
</tr>
<tr class="even">
<td><span class="math inline">\(M_{v,t,s} \sim \text{Bernoulli}(\text{logit}^{-1}(\phi_{v,t,s}))\)</span></td>
<td>Monitoring indicator for trip-based sampling</td>
<td><span class="math inline">\(M_{v,t,s}\)</span>: 1 if set monitored, 0 otherwise</td>
</tr>
</tbody>
</table>
<p><em>Notes:</em><br>
- <span class="math inline">\(M_{v,t,s}\)</span>: Monitoring indicator for set <span class="math inline">\(s\)</span> on trip <span class="math inline">\(t\)</span> of vessel <span class="math inline">\(v\)</span> (1 = monitored, 0 = not monitored)<br>
- <span class="math inline">\(p\)</span>: Proportion of sets to be monitored and reviewed (review and coverage level)<br>
- <span class="math inline">\(\text{bias}_{vessels}\)</span>, <span class="math inline">\(\text{bias}_{trip}\)</span>: Bias factors for vessel/trip selection (higher values = stronger bias towards lower catch rates)<br>
- <span class="math inline">\(x_v\)</span>: Vessel-level random effect (from catch model)<br>
- <span class="math inline">\(z_{v,t}\)</span>: Trip-level random effect (from catch model)</p>
<p><strong>Table S3</strong> Fixed parameter values. Fleet specific parameters was based on values from <span class="citation" data-cites="brown2021electronic">Brown et al. (<a href="#ref-brown2021electronic" role="doc-biblioref">2021</a>)</span>.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 26%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>V</td>
<td>50</td>
<td>Number of vessels in the simulated fleet, representative of medium-sized longline fleet</td>
</tr>
<tr class="even">
<td>μ<sup>trips</sup></td>
<td>10</td>
<td>Mean number of trips per vessel per year, based on typical longline operations</td>
</tr>
<tr class="odd">
<td>θ<sup>trips</sup></td>
<td>1.13</td>
<td>Dispersion parameter for trips per vessel, allows realistic variation in fishing effort</td>
</tr>
<tr class="even">
<td>μ<sup>sets</sup></td>
<td>26</td>
<td>Mean number of sets per trip, typical for longline tuna fishing</td>
</tr>
<tr class="odd">
<td>θ<sup>sets</sup></td>
<td>1.8</td>
<td>Dispersion parameter for sets per trip, reflects operational variation</td>
</tr>
<tr class="even">
<td>θ<sup>catch</sup></td>
<td>0.42</td>
<td>Catch dispersion parameter, controls overdispersion in catch counts</td>
</tr>
<tr class="odd">
<td>p_monitor</td>
<td>0.3/0.2</td>
<td>Proportion of sets monitored (e.g.&nbsp;20%, 30%), as specified by MSC requirements</td>
</tr>
</tbody>
</table>
<p><strong>Table S4</strong> Parameters for monitoring scenarios.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Monitoring Set</th>
<th>Description</th>
<th>Coverage and review rate (p_monitor)</th>
<th>Vessel Bias (bias_v)</th>
<th>Trip Bias (bias_factor)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Baseline</td>
<td>0.3 (30%)</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>Vessel bias</td>
<td>0.3 (30%)</td>
<td>-2</td>
<td>0</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Trip bias</td>
<td>0.3 (30%)</td>
<td>0</td>
<td>-2</td>
</tr>
<tr class="even">
<td>4</td>
<td>Baseline 20%</td>
<td>0.2 (20%)</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>Vessel bias 20%</td>
<td>0.2 (20%)</td>
<td>-2</td>
<td>0</td>
</tr>
<tr class="even">
<td>6</td>
<td>Trip bias 20%</td>
<td>0.2 (20%)</td>
<td>0</td>
<td>-2</td>
</tr>
</tbody>
</table>
<p><strong>Table S5</strong> Species-specific parameter values for catch simulations.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 33%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th>Species Set</th>
<th>Species Type</th>
<th>β₀</th>
<th>σˣ</th>
<th>σᶻ</th>
<th>θ<sup>catch</sup></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Market species</td>
<td>5.6</td>
<td>0.41</td>
<td>0.67</td>
<td>0.42</td>
</tr>
<tr class="even">
<td>2</td>
<td>Market species + high vessel variance</td>
<td>5.6</td>
<td>0.82</td>
<td>0.67</td>
<td>0.42</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Market species + high trip variance</td>
<td>5.6</td>
<td>0.41</td>
<td>1.3</td>
<td>0.42</td>
</tr>
<tr class="even">
<td>4</td>
<td>Bycatch species</td>
<td>0.08</td>
<td>0.55</td>
<td>0.65</td>
<td>0.42</td>
</tr>
<tr class="odd">
<td>5</td>
<td>Rare bycatch species</td>
<td>0.008</td>
<td>0.55</td>
<td>0.65</td>
<td>0.42</td>
</tr>
</tbody>
</table>
</section>
<section id="references" class="level2 unnumbered">


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bellanger2016" class="csl-entry" role="listitem">
Bellanger, Manuel, Claire Macher, and Olivier Guyader. 2016. <span>“A New Approach to Determine the Distributional Effects of Quota Management in Fisheries.”</span> <em>Fisheries Research</em> 181 (September): 116–26. <a href="https://doi.org/10.1016/j.fishres.2016.04.002">https://doi.org/10.1016/j.fishres.2016.04.002</a>.
</div>
<div id="ref-bremner2009" class="csl-entry" role="listitem">
Bremner, Graeme, Peter Johnstone, Tracy Bateson, and Philip Clarke. 2009. <span>“Unreported Bycatch in the New Zealand West Coast South Island Hoki Fishery.”</span> <em>Marine Policy</em> 33 (3): 504–12. <a href="https://doi.org/10.1016/j.marpol.2008.11.006">https://doi.org/10.1016/j.marpol.2008.11.006</a>.
</div>
<div id="ref-brown2021electronic" class="csl-entry" role="listitem">
Brown, Christopher J, Amelia Desbiens, Max D Campbell, Edward T Game, Eric Gilman, Richard J Hamilton, Craig Heberer, David Itano, and Kydd Pollock. 2021. <span>“Electronic Monitoring for Improved Accountability in Western Pacific Tuna Longline Fisheries.”</span> <em>Marine Policy</em> 132: 104664.
</div>
<div id="ref-emery2019" class="csl-entry" role="listitem">
Emery, Timothy J., Rocio Noriega, Ashley J. Williams, and James Larcombe. 2019. <span>“Changes in Logbook Reporting by Commercial Fishers Following the Implementation of Electronic Monitoring in Australian Commonwealth Fisheries.”</span> <em>Marine Policy</em> 104: 135–45. https://doi.org/<a href="https://doi.org/10.1016/j.marpol.2019.01.018">https://doi.org/10.1016/j.marpol.2019.01.018</a>.
</div>
<div id="ref-lynham2014" class="csl-entry" role="listitem">
Lynham, John. 2014. <span>“How Have Catch Shares Been Allocated?”</span> <em>Marine Policy</em> 44 (February): 42–48. <a href="https://doi.org/10.1016/j.marpol.2013.08.007">https://doi.org/10.1016/j.marpol.2013.08.007</a>.
</div>
<div id="ref-Rprogram" class="csl-entry" role="listitem">
R Core Team. 2024. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-rudd2017" class="csl-entry" role="listitem">
Rudd, Merrill B, and Trevor A Branch. 2017. <span>“Does Unreported Catch Lead to Overfishing?”</span> <em>Fish and Fisheries</em> 18 (2): 313–23. <a href="https://doi.org/10.1111/faf.12181">https://doi.org/10.1111/faf.12181</a>.
</div>
<div id="ref-vanbeveren2017" class="csl-entry" role="listitem">
Van Beveren, Elisabeth, Daniel Duplisea, Martin Castonguay, Thomas Doniol-Valcroze, Stéphane Plourde, and Noel Cadigan. 2017. <span>“How Catch Underreporting Can Bias Stock Assessment of and Advice for Northwest Atlantic Mackerel and a Possible Resolution Using Censored Catch.”</span> <em>Fisheries Research</em> 194 (October): 146–54. <a href="https://doi.org/10.1016/j.fishres.2017.05.015">https://doi.org/10.1016/j.fishres.2017.05.015</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>